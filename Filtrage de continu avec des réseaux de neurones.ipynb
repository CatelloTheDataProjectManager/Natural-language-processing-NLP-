{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08039db-a502-45a5-b048-3552f7631480",
   "metadata": {},
   "source": [
    "# Mise en place d’un système de recommandation basé sur un autoencodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65755d6f-bffc-4181-8975-508791d0b9db",
   "metadata": {},
   "source": [
    "### Partie 1 : Préparation des données\n",
    "Chargement et exploration des données\n",
    "- Chargez le fichier bbc-text.csv en utilisant pandas.\n",
    "- Affichez les cinq premières lignes du DataFrame.\n",
    "- Expliquez le rôle des colonnes category et text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4948f0cd-64c7-4fe3-b98f-d769af1a450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category                                               text\n",
      "0           tech  tv future in the hands of viewers with home th...\n",
      "1       business  worldcom boss  left books alone  former worldc...\n",
      "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
      "3          sport  yeading face newcastle in fa cup premiership s...\n",
      "4  entertainment  ocean s twelve raids box office ocean s twelve...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv('bbc-new.csv')\n",
    "\n",
    "# Affichage des cinq premières lignes du DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Explication des colonnes\n",
    "# La colonne 'category' représente la catégorie ou le sujet de l'article.\n",
    "# La colonne 'text' contient le texte de l'article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f90ee-6565-4938-93b0-90a33c4d8474",
   "metadata": {},
   "source": [
    "#### Encodage des catégories\n",
    "- Encodez les valeurs de la colonne category en utilisant LabelEncoder pour obtenir des\n",
    "valeurs numériques.\n",
    "- Ajoutez une colonne category_encoded au DataFrame contenant les catégories encodées.\n",
    "- Affichez les catégories encodées et leur correspondance avec les catégories d’origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6950696-620b-41a5-8aa3-e4c02577cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catégories encodées et leur correspondance :\n",
      "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
      "        category                                               text  \\\n",
      "0           tech  tv future in the hands of viewers with home th...   \n",
      "1       business  worldcom boss  left books alone  former worldc...   \n",
      "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
      "3          sport  yeading face newcastle in fa cup premiership s...   \n",
      "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
      "\n",
      "   category_encoded  \n",
      "0                 4  \n",
      "1                 0  \n",
      "2                 3  \n",
      "3                 3  \n",
      "4                 1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialisation du LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encodage des catégories\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Affichage des catégories encodées et leur correspondance\n",
    "category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Catégories encodées et leur correspondance :\")\n",
    "print(category_mapping)\n",
    "\n",
    "# Affichage des cinq premières lignes du DataFrame avec la nouvelle colonne\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffd28a-d172-460e-8fe8-259f511af8c5",
   "metadata": {},
   "source": [
    "#### Vectorisation TF-IDF\n",
    "- Utilisez TfidfVectorizer pour transformer la colonne text en vecteurs numériques.\n",
    "- Limitez le nombre de caractéristiques à 5000 et appliquez un prétraitement pour ignorer\n",
    "les mots vides (stop words).\n",
    "- Affichez la forme de la matrice obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8034e3cf-389c-4652-a798-8bb4135017f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice TF-IDF : (2225, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialisation du TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Transformation de la colonne text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Affichage de la forme de la matrice obtenue\n",
    "print(\"Forme de la matrice TF-IDF :\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c383c4-3b20-48f0-bc8e-ee7cae806a8f",
   "metadata": {},
   "source": [
    "#### Séparation des données\n",
    "- Séparez les données en ensembles d’entraînement et de test avec un ratio 80%-20%.\n",
    "- Expliquez l’importance de diviser les données en deux ensembles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0694ad-96a6-4c66-ae5c-b01b99240741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : (1780, 5000)\n",
      "Taille de l'ensemble de test : (445, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['category_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage des tailles des ensembles d'entraînement et de test\n",
    "print(\"Taille de l'ensemble d'entraînement :\", X_train.shape)\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e452667-5905-437c-8fe4-0a79673c074c",
   "metadata": {},
   "source": [
    "### Partie 2 : Construction et entraînement de l’autoencodeur\n",
    "\n",
    "Définition de l’architecture de l’autoencodeur\n",
    "- Définissez les dimensions d’entrée et de sortie du modèle en fonction des données d’entrée.\n",
    "- Construisez un modèle avec :\n",
    "- Des couches encodées de dimensions décroissantes (512, 256, 128).\n",
    "- Des couches décodées de dimensions croissantes (128, 256, 512) pour reconstituer les\n",
    "données d’entrée.\n",
    "- Utilisez relu comme fonction d’activation dans les couches cachées et sigmoid dans la\n",
    "couche de sortie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cdf233b-fbf2-42e1-a6a6-018fda2c6c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,560,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │     \u001b[38;5;34m2,565,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,454,344</span> (20.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,454,344\u001b[0m (20.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,454,344</span> (20.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,454,344\u001b[0m (20.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Définir les dimensions d'entrée et de sortie\n",
    "input_dim = tfidf_matrix.shape[1]\n",
    "\n",
    "# Définir l'entrée de l'autoencodeur\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Construire les couches encodées\n",
    "encoded = Dense(512, activation='relu')(input_layer)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "\n",
    "# Construire les couches décodées\n",
    "decoded = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Définir le modèle de l'autoencodeur\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compiler le modèle\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Afficher l'architecture du modèle\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de75ab4-663a-4487-893f-4eb39b38be53",
   "metadata": {},
   "source": [
    "#### Compilation et entraînement\n",
    "- Compilez le modèle en utilisant l’optimiseur Adam avec un taux d’apprentissage de 0,001\n",
    "et une fonction de perte mse.\n",
    "- Entraînez l’autoencodeur sur les données d’entraînement en utilisant 50 époques et une\n",
    "taille de lot de 128.\n",
    "- Évaluez les performances du modèle sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a88b0714-266a-4606-8b52-7630a6c757c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.2455 - val_loss: 0.1566\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0607 - val_loss: 2.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 2.0000e-04 - val_loss: 2.0000e-04\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0000e-04\n",
      "Perte sur les données de test : 0.0001999999803956598\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convertir les matrices creuses en matrices denses\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Compiler le modèle\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Entraîner l'autoencodeur\n",
    "history = autoencoder.fit(X_train_dense, X_train_dense,\n",
    "                          epochs=50,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_test_dense, X_test_dense))\n",
    "\n",
    "# Évaluer les performances du modèle sur les données de test\n",
    "loss = autoencoder.evaluate(X_test_dense, X_test_dense)\n",
    "print(f\"Perte sur les données de test : {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f5be3-53da-46ef-bc89-542c693e19c4",
   "metadata": {},
   "source": [
    "### Partie 3 : Évaluation du modèle\n",
    "Calcul de l’erreur\n",
    "- Implémentez une fonction pour calculer la racine de l’erreur quadratique moyenne (RMSE)\n",
    "entre les données originales et reconstruites.\n",
    "- Calculez le RMSE sur les ensembles d’entraînement et de test.\n",
    "- Interprétez les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88e657a9-9cd2-4f9b-80f8-d5599d818b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "RMSE sur l'ensemble d'entraînement : 0.01414213562373095\n",
      "RMSE sur l'ensemble de test : 0.01414213562373095\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fonction pour calculer le RMSE\n",
    "def calculate_rmse(original, reconstructed):\n",
    "    mse = mean_squared_error(original, reconstructed)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Reconstruire les données d'entraînement et de test\n",
    "X_train_reconstructed = autoencoder.predict(X_train_dense)\n",
    "X_test_reconstructed = autoencoder.predict(X_test_dense)\n",
    "\n",
    "# Calculer le RMSE sur les ensembles d'entraînement et de test\n",
    "rmse_train = calculate_rmse(X_train_dense, X_train_reconstructed)\n",
    "rmse_test = calculate_rmse(X_test_dense, X_test_reconstructed)\n",
    "\n",
    "print(f\"RMSE sur l'ensemble d'entraînement : {rmse_train}\")\n",
    "print(f\"RMSE sur l'ensemble de test : {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b98cd-fc14-4116-a7a8-07d69bf5fe6c",
   "metadata": {},
   "source": [
    "### Partie 4 : Système de recommandation\n",
    "Extraction des représentations encodées\n",
    "- Utilisez le modèle encodeur pour générer des représentations compactes des textes.\n",
    "- Affichez quelques exemples de ces représentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0815a6e3-1990-42fc-8e1a-6ba8e0c6ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Représentations compactes de l'ensemble d'entraînement :\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         3.568185   0.         1.4984218  0.         0.\n",
      "  0.         5.6321926  4.4118915  6.401987   0.         0.\n",
      "  2.095706   3.5047462  0.09026669 4.5948005  2.835757   3.099318\n",
      "  0.         0.         3.95749    0.         3.7217495  0.\n",
      "  4.454132   0.         1.6529427  0.         0.         0.\n",
      "  3.7038362  4.297579   3.1414104  0.12558293 0.         0.\n",
      "  4.2598333  0.         1.6419827  0.         5.8168144  0.\n",
      "  3.4232147  2.4404862  3.6500404  0.         0.         4.772605\n",
      "  7.260083   4.833711   3.4349132  4.38844    0.40744755 4.619599\n",
      "  2.6899898  1.1154891  4.030833   0.         0.         4.874888\n",
      "  3.0669496  5.232492   2.8698444  4.0793185  3.8814511  0.\n",
      "  6.2507267  0.         1.6912237  3.1970408  4.521489   0.\n",
      "  5.1938434  0.         2.592547   0.         4.451839   5.313787\n",
      "  0.         0.         6.286947   4.584465   5.5252376  3.6727908\n",
      "  3.711581   4.3443966  2.0041695  0.         4.2786694  3.5851545\n",
      "  2.366209   5.0583353  4.632352   1.3655282  4.254403   3.9286315\n",
      "  6.3866086  2.5528433  3.2742975  4.89457    0.         3.0214028\n",
      "  1.6697663  0.         3.695568   5.238424   4.495598   6.4646893\n",
      "  3.6070487  5.3283777  2.647179   0.         5.662641   0.\n",
      "  0.         0.         2.683017   4.3100324  3.656466   0.\n",
      "  2.0441072  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         4.3432403  0.         1.8148111  0.         0.\n",
      "  0.         6.911248   5.4282975  7.7900743  0.         0.\n",
      "  2.5833645  4.330072   0.10312418 5.590711   3.4091184  3.7701712\n",
      "  0.         0.         4.817269   0.         4.483472   0.\n",
      "  5.471597   0.         2.0470483  0.         0.         0.\n",
      "  4.5220695  5.2680264  3.8407936  0.12594768 0.         0.\n",
      "  5.2282777  0.         1.9839334  0.         7.0983357  0.\n",
      "  4.1601386  3.0000358  4.462086   0.         0.         5.830793\n",
      "  8.779379   5.860357   4.1151137  5.3825274  0.5044674  5.6511045\n",
      "  3.301959   1.3391006  4.8654857  0.         0.         5.900441\n",
      "  3.7782347  6.4076114  3.4293244  4.9906073  4.7404814  0.\n",
      "  7.621646   0.         2.0404477  3.8961382  5.4867134  0.\n",
      "  6.335934   0.         3.1497633  0.         5.466586   6.4669685\n",
      "  0.         0.         7.6334934  5.575473   6.746616   4.4639134\n",
      "  4.562339   5.2696886  2.4263573  0.         5.177811   4.3364005\n",
      "  2.8580706  6.1906643  5.681852   1.6583245  5.1724143  4.7981076\n",
      "  7.781718   3.1585765  4.0003753  5.948629   0.         3.6703296\n",
      "  2.0342708  0.         4.5645037  6.382515   5.488937   7.8414207\n",
      "  4.411518   6.517508   3.266797   0.         6.8561587  0.\n",
      "  0.         0.         3.192027   5.2397623  4.45636    0.\n",
      "  2.4614394  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         2.955802   0.         1.2832817  0.         0.\n",
      "  0.         4.705051   3.7150934  5.363944   0.         0.\n",
      "  1.7364019  2.9384181  0.06418552 3.8365917  2.3537157  2.5677304\n",
      "  0.         0.         3.300299   0.         3.0221744  0.\n",
      "  3.7321062  0.         1.416163   0.         0.         0.\n",
      "  3.0619302  3.5411568  2.6088562  0.04272585 0.         0.\n",
      "  3.5700028  0.         1.3879007  0.         4.8152018  0.\n",
      "  2.8666315  2.0217884  3.028467   0.         0.         3.9579358\n",
      "  6.0148907  4.023614   2.8674428  3.64228    0.36887893 3.8267431\n",
      "  2.2636175  0.930395   3.3290172  0.         0.         4.0675387\n",
      "  2.6003509  4.343451   2.33967    3.4352617  3.233856   0.\n",
      "  5.2018504  0.         1.3799796  2.6633413  3.7598095  0.\n",
      "  4.3265743  0.         2.1640754  0.         3.6932962  4.4324965\n",
      "  0.         0.         5.220585   3.8504677  4.6303077  3.107694\n",
      "  3.0802023  3.6161816  1.6835346  0.         3.5413861  2.9533465\n",
      "  1.9569939  4.168563   3.8816845  1.1419815  3.5457945  3.223797\n",
      "  5.3306103  2.1118762  2.740176   4.0871944  0.         2.5538027\n",
      "  1.3638918  0.         3.105671   4.3457637  3.748715   5.3946786\n",
      "  3.0238683  4.423739   2.1717756  0.         4.716929   0.\n",
      "  0.         0.         2.190735   3.560095   3.023078   0.\n",
      "  1.6926391  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.1571534  0.         1.3464471  0.         0.\n",
      "  0.         5.0656943  3.9229124  5.6432858  0.         0.\n",
      "  1.8742421  3.173282   0.10315018 4.087237   2.500372   2.7341833\n",
      "  0.         0.         3.5070438  0.         3.2835352  0.\n",
      "  3.9728968  0.         1.5001304  0.         0.         0.\n",
      "  3.335257   3.8647819  2.7729688  0.05155234 0.         0.\n",
      "  3.8180325  0.         1.4249119  0.         5.154874   0.\n",
      "  3.047111   2.2042978  3.2382026  0.         0.         4.202795\n",
      "  6.4252152  4.29607    3.0284076  3.8770971  0.36202464 4.1173067\n",
      "  2.4002538  0.99829555 3.514612   0.         0.         4.32466\n",
      "  2.750481   4.637183   2.5023336  3.590191   3.459033   0.\n",
      "  5.5472965  0.         1.4644893  2.8671315  4.0454206  0.\n",
      "  4.6345515  0.         2.315156   0.         3.9400988  4.7166314\n",
      "  0.         0.         5.5901074  4.095915   4.9387426  3.2592242\n",
      "  3.3063154  3.8597558  1.773701   0.         3.794624   3.1684043\n",
      "  2.0585966  4.4893866  4.161463   1.2095672  3.7712622  3.549906\n",
      "  5.6642427  2.3101459  2.868875   4.378057   0.         2.7011492\n",
      "  1.5183208  0.         3.3376517  4.647097   3.9978948  5.736111\n",
      "  3.2213998  4.7562866  2.3984113  0.         5.040198   0.\n",
      "  0.         0.         2.356408   3.8174837  3.210359   0.\n",
      "  1.8203391  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.679957   0.         1.5755986  0.         0.\n",
      "  0.         5.817992   4.5878086  6.603417   0.         0.\n",
      "  2.1699777  3.6574538  0.08339816 4.734188   2.9331443  3.2030308\n",
      "  0.         0.         4.0775967  0.         3.8166893  0.\n",
      "  4.6496167  0.         1.7495905  0.         0.         0.\n",
      "  3.8587532  4.468769   3.265619   0.12401962 0.         0.\n",
      "  4.418181   0.         1.7039751  0.         5.9635615  0.\n",
      "  3.5077586  2.5475254  3.7871523  0.         0.         4.946033\n",
      "  7.484298   5.0274916  3.5078838  4.5317407  0.4261226  4.7885146\n",
      "  2.8153765  1.1206858  4.157582   0.         0.         5.051639\n",
      "  3.2148588  5.410517   2.899645   4.231847   4.0000215  0.\n",
      "  6.504608   0.         1.7024139  3.2884786  4.6764603  0.\n",
      "  5.358287   0.         2.7295382  0.         4.672388   5.4875274\n",
      "  0.         0.         6.4541783  4.7199388  5.7030787  3.7959857\n",
      "  3.837504   4.4852996  2.0793018  0.         4.4099255  3.6915727\n",
      "  2.4869533  5.2266364  4.79214    1.3765608  4.387507   4.076541\n",
      "  6.57582    2.6861482  3.358976   5.0509033  0.         3.1031196\n",
      "  1.7387463  0.         3.908824   5.4057517  4.6725707  6.685571\n",
      "  3.710303   5.5056286  2.8040795  0.         5.8414693  0.\n",
      "  0.         0.         2.7416642  4.444211   3.7828028  0.\n",
      "  2.0807784  0.        ]]\n",
      "Représentations compactes de l'ensemble de test :\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         4.832479   0.         2.074174   0.         0.\n",
      "  0.         7.703379   6.0247793  8.721815   0.         0.\n",
      "  2.862743   4.8577113  0.13884185 6.2718763  3.8130848  4.238333\n",
      "  0.         0.         5.4313626  0.         5.0474014  0.\n",
      "  6.1117134  0.         2.3243234  0.         0.         0.\n",
      "  5.111577   5.8771296  4.2651863  0.11646481 0.         0.\n",
      "  5.8522835  0.         2.2121224  0.         7.97082    0.\n",
      "  4.664355   3.3418157  4.986425   0.         0.         6.4990644\n",
      "  9.864018   6.6012397  4.681123   6.0369725  0.59039336 6.299202\n",
      "  3.696501   1.5129344  5.4691668  0.         0.         6.622353\n",
      "  4.2201595  7.127145   3.8725357  5.565928   5.3711066  0.\n",
      "  8.527621   0.         2.2858117  4.3623686  6.172608   0.\n",
      "  7.072973   0.         3.5476186  0.         6.133155   7.27255\n",
      "  0.         0.         8.584773   6.23661    7.5864086  5.004461\n",
      "  5.0897937  5.9240932  2.702932   0.         5.871352   4.8898525\n",
      "  3.2398446  6.8951454  6.356746   1.8734779  5.806528   5.369523\n",
      "  8.687929   3.5720718  4.4889164  6.690641   0.         4.162744\n",
      "  2.2701972  0.         5.11483    7.152555   6.1323075  8.8589115\n",
      "  5.002886   7.2792344  3.6723025  0.         7.6935678  0.\n",
      "  0.         0.         3.567144   5.890317   5.00316    0.\n",
      "  2.769889   0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.2579734  0.         1.3472148  0.         0.\n",
      "  0.         5.1857967  4.0418954  5.838271   0.         0.\n",
      "  1.9400928  3.2505507  0.0707626  4.1973715  2.5578814  2.8497496\n",
      "  0.         0.         3.626457   0.         3.3962276  0.\n",
      "  4.1030016  0.         1.5647757  0.         0.         0.\n",
      "  3.4042625  3.9182699  2.8926485  0.11388196 0.         0.\n",
      "  3.937257   0.         1.4768066  0.         5.330294   0.\n",
      "  3.1243706  2.2741513  3.377013   0.         0.         4.3313003\n",
      "  6.5755363  4.4339733  3.0948005  4.0106564  0.37354764 4.186435\n",
      "  2.4832165  0.98315024 3.6877422  0.         0.         4.4377027\n",
      "  2.8360586  4.7975     2.6372693  3.759311   3.5930583  0.\n",
      "  5.701672   0.         1.5488544  2.938998   4.1477222  0.\n",
      "  4.7691135  0.         2.3513112  0.         4.0860004  4.893037\n",
      "  0.         0.         5.7737894  4.1665063  5.080534   3.3602235\n",
      "  3.380906   3.9124277  1.8166199  0.         3.8824618  3.2602499\n",
      "  2.1755733  4.6609893  4.248155   1.2702827  3.9205382  3.5961304\n",
      "  5.828534   2.3930917  2.997382   4.4791703  0.         2.7531936\n",
      "  1.5487044  0.         3.4256325  4.807427   4.1141043  5.9008822\n",
      "  3.351586   4.861786   2.4257474  0.         5.162287   0.\n",
      "  0.         0.         2.458792   3.905988   3.3075817  0.\n",
      "  1.8111584  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.5607257  0.         1.4705848  0.         0.\n",
      "  0.         5.6851397  4.4557137  6.39672    0.         0.\n",
      "  2.1202679  3.5366416  0.0898424  4.602779   2.8489954  3.0959754\n",
      "  0.         0.         3.9732795  0.         3.7229152  0.\n",
      "  4.484566   0.         1.7207943  0.         0.         0.\n",
      "  3.6729095  4.3598175  3.1812906  0.07435669 0.         0.\n",
      "  4.302798   0.         1.6554035  0.         5.8765073  0.\n",
      "  3.482297   2.4480884  3.6567893  0.         0.         4.773166\n",
      "  7.260071   4.8713264  3.420119   4.4198456  0.39406642 4.6248837\n",
      "  2.7154894  1.1351508  4.0057764  0.         0.         4.898923\n",
      "  3.09611    5.220947   2.868531   4.126016   3.956583   0.\n",
      "  6.235726   0.         1.6653484  3.1776545  4.547271   0.\n",
      "  5.1981754  0.         2.6202345  0.         4.486282   5.362308\n",
      "  0.         0.         6.3341184  4.5920544  5.5751996  3.684004\n",
      "  3.7406156  4.386792   2.0141597  0.         4.3182945  3.608073\n",
      "  2.3700984  5.0862513  4.6704636  1.3950576  4.2565823  3.9496582\n",
      "  6.3799753  2.5737906  3.3150184  4.945225   0.         3.03967\n",
      "  1.6893725  0.         3.7554371  5.2889786  4.559424   6.4816556\n",
      "  3.6316402  5.3498697  2.6838942  0.         5.667593   0.\n",
      "  0.         0.         2.6514766  4.342099   3.649569   0.\n",
      "  2.0593607  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.1842341  0.         1.3404887  0.         0.\n",
      "  0.         5.0259366  3.9430795  5.682222   0.         0.\n",
      "  1.8848509  3.1457007  0.11808761 4.0870943  2.4994724  2.770276\n",
      "  0.         0.         3.505182   0.         3.3180113  0.\n",
      "  3.965619   0.         1.5286596  0.         0.         0.\n",
      "  3.3298895  3.813509   2.8150346  0.08141814 0.         0.\n",
      "  3.8135889  0.         1.4249585  0.         5.188434   0.\n",
      "  3.0382354  2.1744685  3.2404697  0.         0.         4.2600694\n",
      "  6.4327903  4.328173   3.0397432  3.9030037  0.36882234 4.115826\n",
      "  2.4022725  1.0166714  3.5841196  0.         0.         4.3325534\n",
      "  2.75313    4.6466923  2.507066   3.6599753  3.436956   0.\n",
      "  5.5808377  0.         1.4699959  2.841986   4.0153513  0.\n",
      "  4.626625   0.         2.310547   0.         3.9983644  4.723706\n",
      "  0.         0.         5.574887   4.081698   4.877073   3.2799993\n",
      "  3.2922585  3.8595047  1.7673844  0.         3.7685537  3.1747918\n",
      "  2.0955074  4.51675    4.160232   1.213164   3.8062644  3.4849615\n",
      "  5.658012   2.3043356  2.9130096  4.3496203  0.         2.711685\n",
      "  1.4791505  0.         3.3323507  4.670677   4.018525   5.743772\n",
      "  3.2226944  4.7545185  2.4034743  0.         5.0338902  0.\n",
      "  0.         0.         2.3426788  3.815742   3.2353702  0.\n",
      "  1.8091054  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         3.4441519  0.         1.4715397  0.         0.\n",
      "  0.         5.531601   4.2389913  6.1414046  0.         0.\n",
      "  2.0487213  3.418146   0.1387343  4.4642887  2.7241373  2.9699018\n",
      "  0.         0.         3.8279696  0.         3.5772247  0.\n",
      "  4.3871875  0.         1.6288449  0.         0.         0.\n",
      "  3.6250513  4.2279515  3.0749214  0.06506375 0.         0.\n",
      "  4.140174   0.         1.6187968  0.         5.667131   0.\n",
      "  3.3280213  2.38961    3.544376   0.         0.         4.6082478\n",
      "  7.046226   4.740553   3.2737992  4.282147   0.39996982 4.4788947\n",
      "  2.642124   1.0783669  3.8469377  0.         0.         4.694491\n",
      "  2.9970102  5.068301   2.7364795  3.9803169  3.8139827  0.\n",
      "  6.0466666  0.         1.6397502  3.1137033  4.402924   0.\n",
      "  5.058016   0.         2.5392542  0.         4.316616   5.167468\n",
      "  0.         0.         6.0978556  4.457028   5.4146633  3.5396683\n",
      "  3.5975633  4.1884227  1.9232005  0.         4.1518254  3.4246361\n",
      "  2.2660062  4.9373784  4.520752   1.3127972  4.1225214  3.776021\n",
      "  6.1658764  2.5032358  3.183805   4.772878   0.         2.932271\n",
      "  1.605893   0.         3.600404   5.077249   4.4083138  6.2837944\n",
      "  3.5513532  5.193551   2.5691185  0.         5.489615   0.\n",
      "  0.         0.         2.554007   4.1767306  3.5459862  0.\n",
      "  1.9896816  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Extraire le modèle encodeur\n",
    "encoded_input = Input(shape=(input_dim,))\n",
    "encoder_layers = autoencoder.layers[1:4]  # Les trois premières couches sont les couches de l'encodeur\n",
    "encoded_output = encoded_input\n",
    "for layer in encoder_layers:\n",
    "    encoded_output = layer(encoded_output)\n",
    "\n",
    "encoder = Model(encoded_input, encoded_output)\n",
    "\n",
    "# Générer des représentations compactes\n",
    "encoded_train = encoder.predict(X_train_dense)\n",
    "encoded_test = encoder.predict(X_test_dense)\n",
    "\n",
    "# Afficher quelques exemples de ces représentations\n",
    "print(\"Représentations compactes de l'ensemble d'entraînement :\")\n",
    "print(encoded_train[:5])  # Afficher les 5 premières représentations de l'ensemble d'entraînement\n",
    "\n",
    "print(\"Représentations compactes de l'ensemble de test :\")\n",
    "print(encoded_test[:5])  # Afficher les 5 premières représentations de l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60a6f0-9faf-4bf1-9c82-52141f472035",
   "metadata": {},
   "source": [
    "#### Implémentation d’une fonction de recommandation\n",
    "- Créez une fonction recommend qui prend en entrée :\n",
    "- Un texte d’utilisateur.\n",
    "- Le nombre de recommandations souhaitées (par défaut : 5).\n",
    "\n",
    "Cette fonction doit :\n",
    "- Transformer le texte d’entrée en vecteur TF-IDF.\n",
    "- Extraire sa représentation encodée.\n",
    "- Calculer la similarité entre cette représentation et celles des textes du dataset.\n",
    "- Retourner les textes les plus similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ea7896-9355-455e-b22a-25b54e2e8aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Textes recommandés :\n",
      "borussia dortmund near bust german football club and former european champion borussia dortmund has warned it will go bankrupt if rescue talks with creditors fail.  the company s shares tumbled after it said it has  entered a life-threatening profitability and financial situation . borussia dortmund has posted record losses and missed rent payments on its westfallen stadium. chief executive gerd niebaum stepped down last week and creditors are now pushing for greater control. shares in borussia dortmund  germany s only stock-market listed football club  dropped by almost 23% to 2.05 euros during early afternoon trading.  fund manager florian hamm - borussia dortmund s largest investor - said he would only invest more money in the company if he got a greater say in how it is run.  i demand better transparency   he is quoted as saying by germany s manger magazin. the club has also faced calls to appoint executives from outside the club.  borussia dortmund posted a record loss of 68m euros ($89m; £47m) in the 12 months through june. it made a loss of 27.2m euros in the first half of the current fiscal year and said that total debts will increase to 134.7m euros by the middle of 2006 unless a restructuring plan is pushed through.  this is the bill for their mismanagement over the past years   said hvb analyst peter-thilo halser. the club appointed an auditor  who has recommended a number of steps  including deferring the rent due on the stadium and suspending debt repayments until at least the 2006-2007 fiscal year. stephen schechter  a uk investment banker who has held talks with borussia dortmund over a possible bond sale  said the club needs a capital injection of 35m euros.  they need strong people on the board who do not have a history with the club   he said.\n",
      "tarantino  to make friday sequel  director quentin tarantino is in talks to write and direct a new instalment in the friday the 13th horror franchise  according to the hollywood reporter.  the film-maker will reportedly meet executives from new line cinema this week to discuss the 12th film in the long-running  stalk and slash  series. the original film  released in 1980  has spawned ten sequels based around mask-wearing murderer jason voorhees. the most recent  freddy vs jason  was released in summer 2003. that film saw jason battle freddy krueger  star of the nightmare on elm street franchise. according to the industry newspaper  new line had been trying to make another sequel involving ash  the hero of the evil dead movies  but was unable to agree terms with director sam raimi. tarantino is said to be intrigued by the prospect of building a new film around one of the horror genre s most recognised figures. first  however  he is scheduled to direct the season finale of us television series csi: crime scene investigation. filming is due to start in early april. tarantino s episode  for which he also wrote the original story  will be broadcast in the us on 19 may.\n",
      "wolves appoint hoddle as manager glenn hoddle will be unveiled as the new wolves manager on tuesday.  the club have confirmed that the former england coach will be unveiled as the successor to dave jones at a news conference at molineux at 1100 gmt. hoddle has been linked with a return to former club southampton but wolves have won the race for his services. he has been out of the game since being sacked at spurs in september 2003 and worked alongside wolves caretaker boss stuart gray at southampton. hoddle began his managerial career as player-boss with swindon before moving on to chelsea and then taking up the england job.  his spell in charge of the national side came to an end after the 1998 world cup when he made controversial remarks about the disabled in a newspaper interview. the 47-year-old later returned to management with southampton  where he again succeeded jones - as he has now done at wolves. he engineered an upturn in saints  fortunes before being lured to white hart lane by tottenham - the club where he made his name as a player. that relationship turned sour at the start of the last campaign and he left the london club early last season. since then he has applied unsuccessfully for the post of france manager and had also been linked with a return to southampton. wolves are currently 17th in the championship and have a home game against millwall on tuesday.\n",
      "vera drake s bafta triumph hope at the bafta film awards on saturday night  there is the prospect that a home-grown movie could walk off with a clutch of trophies.  vera drake  mike leigh s tale about a 1950s backstreet abortionist  is nominated in 11 categories. these include best film  best director and best actress shortlist for imelda staunton who plays the eponymous character. the film has spent months being lauded with prizes  from the venice film festival to five awards from the london critics  circle on wednesday night.  the baftas has a tradition of honouring british cinema  and this year vera drake is the obvious candidate to be heaped with praise. empire magazine s reviews editor dan jolin said the film had  a very good chance  of doing well on saturday  predicting that it would collect five or six awards.  i don t think it s going to do a lord of the rings-style sweep  but imelda staunton is a shoo-in for best actress   he said.   a best director prize for mike leigh and best british film are also likely and it could steal some awards from heavily-nominated competitors the aviator and finding neverland.  mr jolin tipped another contender - most likely the aviator - to walk away with the bafta for best film  and added that finding neverland had been lavished with nominations but not trophies. strong oscar contenders million dollar baby and sideways did not figure in the bafta nominations  giving vera drake greater potential to walk away with the big prizes.   there is a sense that this film is ours and we should slap our own guys on the back. out of all the films in the running for the baftas  vera drake is the true blue british one.    if mike leigh is going to win awards for anything  it should be vera drake at this year s baftas   said mr jolin  adding that the film was probably his most technically accomplished and lavish work yet. mr jolin also tipped phil davis for a best supporting actor prize for his role in vera drake but felt that heather craney could be outdone by kate winslet or natalie portman in the supporting actress category.  if there is anywhere where this film is going to win  it will be at the baftas   he said.  the guardian s film critic peter bradshaw felt that there  might well be  a sweep of awards for vera drake on saturday night.  i hope that bafta voters will respond to the extremely high standard of acting from the whole cast of the film. if bafta can t do so  what hope is there   he said. mr bradshaw felt that mike leigh s  masterpiece  was entitled to the best film award - leaving dead man s shoes  harry potter and the prisoner of azkaban  my summer of love and shaun of the dead to slug it out for the best british film trophy.  i will be cheering if vera drake wins a whole host of awards   he added.\n",
      "sbc plans post-takeover job cuts us phone company sbc communications said it expects to cut around 12 800 jobs following its $16bn (£8.5bn) takeover of former parent at&t.  sbc said 5 125 positions would go as a result of network efficiencies. another 1 700 will go from its sales department  3 400 from business operations and 2 600 across legal  advertising and public relations. sbc currently employs 163 000 people while at&t employs 47 000. the takeover was announced on monday. the deal will be financed with $15bn of shares as well as a $1bn special dividend paid to at&t shareholders.  it effectively marks the end of at&t  which was founded in 1875 by telephone pioneer alexander graham bell and is one of the us s best-known companies. sbc and at&t said estimated cost savings of at least $2bn from 2008 were a main driver for the merger. at&t is a long-distance telecoms firm  while sbc is mainly focused on the local market in the western us. both also have data network businesses. the takeover is subject to approval by at&t s shareholders and regulators. the companies said they expected to complete the agreement during the first half of 2006.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fonction de recommandation\n",
    "def recommend(user_text, num_recommendations=5):\n",
    "    # Transformer le texte d'entrée en vecteur TF-IDF\n",
    "    user_tfidf = tfidf_vectorizer.transform([user_text])\n",
    "\n",
    "    # Extraire la représentation encodée du texte d'entrée\n",
    "    user_encoded = encoder.predict(user_tfidf.toarray())\n",
    "\n",
    "    # Calculer la similarité entre la représentation encodée du texte d'entrée et celles des textes du dataset\n",
    "    similarities = cosine_similarity(user_encoded, encoded_train)\n",
    "\n",
    "    # Obtenir les indices des textes les plus similaires\n",
    "    similar_indices = similarities.argsort()[0][-num_recommendations:][::-1]\n",
    "\n",
    "    # Retourner les textes les plus similaires\n",
    "    recommended_texts = df.iloc[similar_indices]['text'].tolist()\n",
    "    return recommended_texts\n",
    "\n",
    "# Exemple d'utilisation de la fonction de recommandation\n",
    "user_text = \"Votre texte d'entrée ici\"\n",
    "recommendations = recommend(user_text, num_recommendations=5)\n",
    "print(\"Textes recommandés :\")\n",
    "for text in recommendations:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07ce23-ea37-42cd-99ee-44c519fba71e",
   "metadata": {},
   "source": [
    "#### Test de la fonction de recommandation\n",
    "- Testez la fonction avec un texte exemple (par exemple : The stock market shows significant\n",
    "growth).\n",
    "- Affichez les recommandations obtenues, avec leurs catégories et contenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "528d2f18-7f5c-4e4d-98fe-dd505b4e2953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Textes recommandés :\n",
      "Catégorie : entertainment\n",
      "Contenu : prince crowned  top music earner  prince earned more than any other pop star in 2004  beating artists such madonna and elton john in us magazine rolling stone s annual list.  the singer banked $56.5m (£30.4m) from concerts  album and publishing sales with his musicology tour and album. he kept madonna in second place  as she earned $54.9m (£29.5m) while embarking on her global re-invention tour. veterans simon and garfunkel were in 10th place  their comeback tour helping them earn $24.9m (£13.4m) last year.   prince returned to centre stage after a decade in the commercial wilderness   the magazine reported. the singer s 2004 tour took $90.3m (£48.5m) in ticket sales and he sold 1.9 million copies of his latest album musicology.  although she grossed more than prince last year  madonna remained in second place because of the  monumental  production costs of her tour. heavy metal band metallica s madly in anger with the world tour helped push their 2004 earnings up to $43.1m (£23.1m). they were ahead of sir elton john  who took fourth place and almost $42.7m (£23m) from performances including a debut on the las vegas strip. other seasoned performers in the list included rod stewart  whose sold-out shows and third volume of the great american songbook covers album helped net him £35m (£19m). the highest-ranking rap act in the list was 50 cent  who at number 19 took $24m (£13m) to the bank.\n",
      "--------------------------------------------------\n",
      "Catégorie : business\n",
      "Contenu : saab to build cadillacs in sweden general motors  the world s largest car maker  has confirmed that it will build a new medium-sized cadillac bls at its loss-making saab factory in sweden.  the car  unveiled at the geneva motor show  is intended to compete in the medium-sized luxury car market. it will not be sold in the us  said gm europe president carl-peter forster. as part of its efforts to make the us marque appeal to european drivers  the car will be the first cadillac with a diesel engine.  gm s announcement should go some way to allay fears of the saab factory s closure. the factory in trollhaettan has been at the centre of rumours about gm s planned severe cutbacks in its troubled european operations. but the group s new commitment to the swedish factory may not be welcomed by the group s opel workers in ruesselsheim  germany. they may now have to face a larger proportion of gm s cuts.  neither will the announcement be seen as unalloyed good news in sweden  since it reflects saab s failure to make significant inroads into the lucrative european luxury car market. for years  saab has consistently said it is competing head-on with bmw  mercedes and jaguar. the segment s leaders do not agree.  gm s plans to build the american marque in sweden is part of its efforts to push it as an alternative luxury brand for european drivers. in the us  it has long been established as an upmarket brand - even the presidential limousine carries the badge. yet it could prove tough for cadillac to steal market share from the majors in europe. other luxury car makers  most notably the toyota subsidiary lexus  have enjoyed tremendous success in the us without managing to make significant inroads in europe. there  german marques mercedes benz and bmw have retained their stranglehold on the luxury market.  bringing cadillac production to sweden should help introduce desperately-needed scale to the saab factory  which currently produces fewer than 130 000 cars per year. that is about half of what major car makers consider sufficient numbers for profitable operations  and saab is losing money fast - albeit with losses halved in 2004 to $200m (£104m; 151m euros) from $500m the previous year. beyond the 12 000 job cuts announced last year at its european operations  gm is reducing expenditure by building saabs  opels - badged as vauxhalls in the uk - and now cadillacs on the same framework  and by allowing the different brands to share parts. another way to further reduce saab s losses could be to shift some of the production of saabs to the us  a market where drivers have adopted it as an upmarket european car. doing so would remove the exposure to the weak us dollar  which is making saabs more expensive to us consumers. but not everyone in the industry agree that it would be the best way forward.  we know that in five years the us dollar will be stronger than it is today   the chief executive of a leading european car maker told bbc news. the current trend towards us production was  stupid   he said.  in a separate announcement  gm unveiled a new scheme to allow european consumers the chance to test drive its opel and vauxhall models. it is to deploy a fleet of 35 000 test cars across 40 countries  inviting potential buyers to try out a vehicle for 24-hours. it follows a similar initiative by gm in the us. gm said it wanted to change  customers  perceptions  about opel and vauxhall cars  showing them that the quality had improved in recent years.\n",
      "--------------------------------------------------\n",
      "Catégorie : sport\n",
      "Contenu : charvis set to lose fitness bid flanker colin charvis is unlikely to play any part in wales  final two games of the six nations.  charvis has missed all three of wales  victories with an ankle injury and his recovery has been slower than expected.  he will not figure in the scotland game and is now thought unlikely to be ready for the final game   said wales physio mark davies. sonny parker is continuing to struggle with a neck injury  but hal luscombe should be fit for the murrayfield trip. centre parker has only a  slim chance  of being involved against the scots on 13 march  so luscombe s return to fitness after missing the france match with hamstring trouble is a timely boost.  said wales assistant coach scott johnson:  we re positive about hal and hope he ll be raring to go.  he comes back into the mix again  adds to the depth and gives us other options.   replacement hooker robin mcbryde remains a doubt after picking up knee ligament damage in paris last saturday.  we re getting that reviewed and we should know more by the end of the week how robin s looking   added johnson.  we re hopeful but it s too early to say at this stage.  steve jones from the dragons is likely to be drafted in if mcbryde fails to recover.\n",
      "--------------------------------------------------\n",
      "Catégorie : entertainment\n",
      "Contenu : artists  secret postcards on sale postcards by artists including damien hirst and tracey emin have sold just hours after the opening of the royal academy of arts annual secrets sale.  the identity of the artist remains unknown until each work is bought and the signature is revealed on the back.  there are still some big names left  such as mario testino   said rca spokeswoman sue bradburn. all postcards are priced at £35. the sale opened at 8am on friday and will close at 6pm on saturday. ms bradburn said there was a big queue at the start of the sale but it had now gone down.  she said the people that had bought the famous name postcards had arrived early and had spent time studying each work.  they would have known what to look for.  the exhibition has been open for viewing since 19 november. film director ken loach  fashion designer hussein chalayan and former blur guitarist graham coxon have all designed postcards for the sale. some of the contributing artists are students or recent graduates of the royal college of art and other leading art colleges. money raised from the sale will go towards the rca s fine art student award fund which supports students with grants and bursaries. the famous sale is now in its 11th year.\n",
      "--------------------------------------------------\n",
      "Catégorie : politics\n",
      "Contenu : csa chief who  quit  still in job the head of the  failing  child support agency widely reported to have resigned three months ago is still at the helm of the troubled organisation.  doug smith s departure was announced by work secretary alan johnson on 17 november as mps grilled him over the agency s poor performance. his  resignation  was referred to by both tory and lib dem leaders during that day s prime ministers questions. officials now say he did not resign but will move on under civil service rules.  mr smith s departure was reported widely at the time as his shouldering the blame for the failings of the child support agency. in january the mps who make up the commons work and pensions committee published a highly critical report into the  failing  agency noting the chief executive  has now left  and hoping  the new leadership will bring a fresh approach to what is a failing organisation .  on that day s today programme mr johnson was asked why mr smith had been allowed to resign rather than be sacked. he replied:  the chief executive decided it was time to move on  there is a new chief executive coming in.  it now emerges that the widespread belief mr smith  made commander of the order of the bath in the new year honours  had left  was wrong. a department for work and pensions spokeswoman confirmed mr smith was still in post and that he would continue in the job until a replacement was found.  no date was ever given for doug smith s departure   she said adding that the post had been advertised.  tory work and pensions spokesman david willetts said families affected by csa failings would wonder why mr smith was still in his job three months after his departure was announced. the csa has been surrounded by controversy since its introduction in 1993 to assess and enforce child support payments by absent parents.  the work and pensions committee launched their inquiry into the csa s performance after it became clear that  despite the introduction of a simpler system of calculating maintenance payments for new cases in 2003  a backlog of claims was still building up. it is currently chasing outstanding payments of more than £720m  while a further £947m has been designated as  unrecoverable . the mps found american it giant eds  £456m system was  nowhere near being fully functional and the number of dissatisfied  disenchanted and angry customers continues to escalate .  in november  when he surprised mps and the watching media by announcing mr smith s departure  mr johnson said:  i should tell you that doug has decided that now is the time to stand aside and to allow a new chief executive to tackle the challenges ahead.  doug has exceeded the four years that senior civil servants are now expected to remain in a particular post.  so doug believes that we have reached the natural breakpoint at which he can hand over the reins.  lib dem sir archy kirkwood  who chairs the commons work and pensions committee  said that when mr johnson had announced mr smith was going he got the  clear impression  the csa chief was retiring though it had since emerged that was not the case  and he may be seeking new employment opportunities.  he added his committee was  duty bound  to allow the work and pensions secretary to get new management into place in the csa and it would be  premature  to say anything further on the issue at the moment. but committee member and tory mp nigel waterson said he was  amazed  mr smith was still in his job.  when mr smith and the secretary of state came to give evidence  we were led to believe he was going shortly   he said.  even if he was working out three months notice  he should have been clearing his desk by now.  asked on thursday about mr smith s position mr johnson told bbc radio 4 s world at one he thought it was a  non-story . he added that he had been absolutely open when he announced mr smith s departure to the select committee and how people chose to interpret it was a  different thing .  the major issue is have we got a new chief executive coming into this very important agency as quickly as possible and have we gone through the right selection process to make sure we ve got the right people   he added.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Définir un texte exemple\n",
    "user_text = \"The stock market shows significant growth\"\n",
    "\n",
    "# Appeler la fonction de recommandation\n",
    "recommendations = recommend(user_text, num_recommendations=5)\n",
    "\n",
    "# Afficher les recommandations obtenues avec leurs catégories et contenus\n",
    "print(\"Textes recommandés :\")\n",
    "for text in recommendations:\n",
    "    # Trouver l'index du texte recommandé dans le DataFrame\n",
    "    index = df[df['text'] == text].index[0]\n",
    "    category = df.loc[index, 'category']\n",
    "    content = df.loc[index, 'text']\n",
    "    print(f\"Catégorie : {category}\")\n",
    "    print(f\"Contenu : {content}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a57a97-5b04-4305-9801-1147b1d5f0b1",
   "metadata": {},
   "source": [
    "# Rapport Technique : Construction et Évaluation d'un Autoencodeur pour la Recommandation de Textes\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce rapport technique présente les étapes de construction, d'entraînement et d'évaluation d'un autoencodeur pour la recommandation de textes. Nous avons utilisé un ensemble de données de textes pour entraîner l'autoencodeur et générer des représentations compactes des textes. Ensuite, nous avons implémenté un système de recommandation basé sur ces représentations.\n",
    "\n",
    "## Partie 1 : Préparation des Données\n",
    "\n",
    "### Chargement et Exploration des Données\n",
    "\n",
    "Nous avons chargé le fichier `bbc-text.csv` en utilisant pandas et exploré les cinq premières lignes du DataFrame. Les colonnes `category` et `text` ont été expliquées :\n",
    "\n",
    "- **category** : Représente la catégorie ou le sujet de l'article.\n",
    "- **text** : Contient le texte complet de l'article.\n",
    "\n",
    "### Encodage des Catégories\n",
    "\n",
    "Nous avons utilisé `LabelEncoder` pour encoder les valeurs de la colonne `category` en valeurs numériques et ajouté une nouvelle colonne `category_encoded` au DataFrame.\n",
    "\n",
    "### Vectorisation TF-IDF\n",
    "\n",
    "Nous avons utilisé `TfidfVectorizer` pour transformer la colonne `text` en vecteurs numériques, en limitant le nombre de caractéristiques à 5000 et en ignorant les mots vides (stop words). La forme de la matrice TF-IDF obtenue a été affichée.\n",
    "\n",
    "## Partie 2 : Construction et Entraînement de l'Autoencodeur\n",
    "\n",
    "### Définition de l'Architecture de l'Autoencodeur\n",
    "\n",
    "Nous avons défini un autoencodeur avec les dimensions d'entrée et de sortie basées sur les données d'entrée. L'architecture de l'autoencodeur comprend :\n",
    "\n",
    "- **Couches encodées** : Dimensions décroissantes (512, 256, 128).\n",
    "- **Couches décodées** : Dimensions croissantes (128, 256, 512) pour reconstituer les données d'entrée.\n",
    "- **Fonctions d'activation** : `relu` dans les couches cachées et `sigmoid` dans la couche de sortie.\n",
    "\n",
    "### Compilation et Entraînement\n",
    "\n",
    "Nous avons compilé le modèle en utilisant l'optimiseur Adam avec un taux d'apprentissage de 0,001 et une fonction de perte `mse`. Le modèle a été entraîné sur les données d'entraînement en utilisant 50 époques et une taille de lot de 128. Les performances du modèle ont été évaluées sur les données de test.\n",
    "\n",
    "## Partie 3 : Évaluation du Modèle\n",
    "\n",
    "### Calcul de l'Erreur\n",
    "\n",
    "Nous avons implémenté une fonction pour calculer la racine de l'erreur quadratique moyenne (RMSE) entre les données originales et reconstruites. Le RMSE a été calculé sur les ensembles d'entraînement et de test.\n",
    "\n",
    "### Interprétation des Résultats\n",
    "\n",
    "- **RMSE sur l'ensemble d'entraînement** : Indique à quel point les données reconstruites par l'autoencodeur sont proches des données originales pour les données d'entraînement.\n",
    "- **RMSE sur l'ensemble de test** : Indique à quel point les données reconstruites par l'autoencodeur sont proches des données originales pour les données de test.\n",
    "- **Comparaison des RMSE** : Si le RMSE sur l'ensemble de test est significativement plus élevé que le RMSE sur l'ensemble d'entraînement, cela peut indiquer un surapprentissage.\n",
    "\n",
    "## Partie 4 : Système de Recommandation\n",
    "\n",
    "### Extraction des Représentations Encodées\n",
    "\n",
    "Nous avons utilisé le modèle encodeur pour générer des représentations compactes des textes et affiché quelques exemples de ces représentations.\n",
    "\n",
    "### Implémentation d'une Fonction de Recommandation\n",
    "\n",
    "Nous avons créé une fonction `recommend` qui prend en entrée un texte d'utilisateur et le nombre de recommandations souhaitées (par défaut : 5). La fonction :\n",
    "\n",
    "1. Transforme le texte d'entrée en vecteur TF-IDF.\n",
    "2. Extrait sa représentation encodée.\n",
    "3. Calcule la similarité entre cette représentation et celles des textes du dataset.\n",
    "4. Retourne les textes les plus similaires.\n",
    "\n",
    "### Test de la Fonction de Recommandation\n",
    "\n",
    "Nous avons testé la fonction avec un texte exemple : \"The stock market shows significant growth\". Les recommandations obtenues ont été affichées avec leurs catégories et contenus.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Ce rapport technique a démontré la construction, l'entraînement et l'évaluation d'un autoencodeur pour la recommandation de textes. Le système de recommandation basé sur les représentations compactes générées par l'autoencodeur a été implémenté et testé avec succès. Les résultats obtenus montrent que l'autoencodeur est capable de reconstruire efficacement les données d'entrée et que le système de recommandation peut suggérer des textes similaires de manière pertinente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
